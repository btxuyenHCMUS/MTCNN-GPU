{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from src.get_nets import PNet, RNet, ONet\n",
    "from src.box_utils import nms, calibrate_box, get_image_boxes, convert_to_square\n",
    "from src.first_stage import run_first_stage\n",
    "from src.visualization_utils import show_bboxes\n",
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnet = PNet()\n",
    "rnet = RNet()\n",
    "onet = ONet()\n",
    "onet.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this value is too low the algorithm will use a lot of memory\n",
    "min_face_size = 15.0  \n",
    "\n",
    "# for probabilities\n",
    "thresholds = [0.6, 0.7, 0.8]\n",
    "\n",
    "# for NMS\n",
    "nms_thresholds=[0.7, 0.7, 0.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "image = Image.open('images/family.jpeg')\n",
    "image.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build an image pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "width, height = image.size\n",
    "min_length = min(height, width)\n",
    "\n",
    "min_detection_size = 12\n",
    "factor = 0.707  # sqrt(0.5)\n",
    "\n",
    "# scales for scaling the image\n",
    "scales = []\n",
    "\n",
    "# scales the image so that\n",
    "# minimum size that we can detect equals to\n",
    "# minimum face size that we want to detect\n",
    "m = min_detection_size/min_face_size\n",
    "min_length *= m\n",
    "\n",
    "factor_count = 0\n",
    "while min_length > min_detection_size:\n",
    "    scales.append(m*factor**factor_count)\n",
    "    min_length *= factor\n",
    "    factor_count += 1\n",
    "\n",
    "print('scales:', ['{:.2f}'.format(s) for s in scales])\n",
    "print('number of different scales:', len(scales))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bounding_boxes = []\n",
    "\n",
    "# run P-Net on different scales \n",
    "for s in scales:\n",
    "    boxes = run_first_stage(image, pnet, scale=s, threshold=thresholds[0])\n",
    "    bounding_boxes.append(boxes)\n",
    "\n",
    "# collect boxes (and offsets, and scores) from different scales\n",
    "bounding_boxes = [i for i in bounding_boxes if i is not None]\n",
    "bounding_boxes = np.vstack(bounding_boxes)\n",
    "print('number of bounding boxes:', len(bounding_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bboxes(image, bounding_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMS + calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "keep = nms(bounding_boxes[:, 0:5], nms_thresholds[0])\n",
    "bounding_boxes = bounding_boxes[keep]\n",
    "\n",
    "# use offsets predicted by pnet to transform bounding boxes\n",
    "bounding_boxes = calibrate_box(bounding_boxes[:, 0:5], bounding_boxes[:, 5:])\n",
    "# shape [n_boxes, 5]\n",
    "\n",
    "bounding_boxes = convert_to_square(bounding_boxes)\n",
    "bounding_boxes[:, 0:4] = np.round(bounding_boxes[:, 0:4])\n",
    "print('number of bounding boxes:', len(bounding_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bboxes(image, bounding_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img_boxes = get_image_boxes(bounding_boxes, image, size=24)\n",
    "img_boxes = Variable(torch.FloatTensor(img_boxes), volatile=True)\n",
    "output = rnet(img_boxes)\n",
    "offsets = output[0].data.numpy()  # shape [n_boxes, 4]\n",
    "probs = output[1].data.numpy()  # shape [n_boxes, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "keep = np.where(probs[:, 1] > thresholds[1])[0]\n",
    "bounding_boxes = bounding_boxes[keep]\n",
    "bounding_boxes[:, 4] = probs[keep, 1].reshape((-1,))\n",
    "offsets = offsets[keep]\n",
    "\n",
    "print('number of bounding boxes:', len(bounding_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bboxes(image, bounding_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMS + calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "keep = nms(bounding_boxes, nms_thresholds[1])\n",
    "bounding_boxes = bounding_boxes[keep]\n",
    "bounding_boxes = calibrate_box(bounding_boxes, offsets[keep])\n",
    "bounding_boxes = convert_to_square(bounding_boxes)\n",
    "bounding_boxes[:, 0:4] = np.round(bounding_boxes[:, 0:4])\n",
    "print('number of bounding boxes:', len(bounding_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bboxes(image, bounding_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img_boxes = get_image_boxes(bounding_boxes, image, size=48)\n",
    "img_boxes = Variable(torch.FloatTensor(img_boxes), volatile=True)\n",
    "output = onet(img_boxes)\n",
    "landmarks = output[0].data.numpy()  # shape [n_boxes, 10]\n",
    "offsets = output[1].data.numpy()  # shape [n_boxes, 4]\n",
    "probs = output[2].data.numpy()  # shape [n_boxes, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "keep = np.where(probs[:, 1] > thresholds[2])[0]\n",
    "bounding_boxes = bounding_boxes[keep]\n",
    "bounding_boxes[:, 4] = probs[keep, 1].reshape((-1,))\n",
    "offsets = offsets[keep]\n",
    "landmarks = landmarks[keep]\n",
    "\n",
    "# compute landmark points\n",
    "width = bounding_boxes[:, 2] - bounding_boxes[:, 0] + 1.0\n",
    "height = bounding_boxes[:, 3] - bounding_boxes[:, 1] + 1.0\n",
    "xmin, ymin = bounding_boxes[:, 0], bounding_boxes[:, 1]\n",
    "landmarks[:, 0:5] = np.expand_dims(xmin, 1) + np.expand_dims(width, 1)*landmarks[:, 0:5]\n",
    "landmarks[:, 5:10] = np.expand_dims(ymin, 1) + np.expand_dims(height, 1)*landmarks[:, 5:10]\n",
    "    \n",
    "print('number of bounding boxes:', len(bounding_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bboxes(image, bounding_boxes, landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMS + calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bounding_boxes = calibrate_box(bounding_boxes, offsets)\n",
    "keep = nms(bounding_boxes, nms_thresholds[2], mode='min')\n",
    "bounding_boxes = bounding_boxes[keep]\n",
    "landmarks = landmarks[keep]\n",
    "print('number of bounding boxes:', len(bounding_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bboxes(image, bounding_boxes, landmarks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
