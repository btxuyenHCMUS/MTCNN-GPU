{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "5.MTCNN.report.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cvB6pBMICZzA",
        "OKq1RiQIEWsS",
        "9ZWxcWD3EWsS"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny2nWL_IEWsL"
      },
      "source": [
        "<h1 style=\"color: blue; text-align: center;\">Multi-task Cascaded Convolutional Networks (MTCNN) for Face Detection and Facial Landmark Alignment Using Parallel</h1>\n",
        "\n",
        "---\n",
        "\n",
        "<h2 style=\"color: gray; text-align: right;\">Members of Team:</h2>\n",
        "\n",
        "| MSSV | Full Name | ID Github |\n",
        "| ---- | ---- | -------- |\n",
        "| 1612835 | Bùi Trọng Xuyến | btxuyenhcmus |\n",
        "| 1612165 | Nguyễn Đào Vinh Hải | NDVHaiHCMUS |\n",
        "| 1612859 | Nguyễn Đình Hữu | NguyenDinhHuu-HCMUS |"
      ],
      "id": "Ny2nWL_IEWsL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cYJ9VOhEWsN"
      },
      "source": [
        "---\n",
        "# 1.  Mô tả ứng dụng\n",
        "\n",
        "**Input:** Một tấm ảnh RGB, Video, Video livestream.\n",
        "\n",
        "**Output:** Một tấm ảnh RGB hoặc một video live trực tiếp được bounding các object và đánh dấu các vị trí trên khuôn mặt.\n",
        "\n",
        "**Ý nghĩa thực tế của ứng dụng:**\n",
        "- Bài toán face detection là một bài toán mang lại rất nhiều lợi ích hiện nay: auto focus đối tượng trên máy ảnh, camera giám sát, smart house, tự động phát hiện khuông mặt để tag trong các mạng xã hội, bước đầu cho bài toán face reccorgnition,...\n",
        "\n",
        "**Ứng dụng này cần được tăng tốc**\n",
        "- Khi xử lý với video khi lượng frame đưa xuống quá nhanh, kết quả trả về của mô hình không kiệp đáp ứng tạo nên độ trễ.\n",
        "\n",
        "**Ứng dụng có thể song song hóa:**\n",
        "- Song song hóa các phép tích chập trong mô hình.\n",
        "- Các phép toán trên matrix.\n",
        "\n",
        "\n",
        "![index](https://kpzhang93.github.io/MTCNN_face_detection_alignment/paper/examples.png)\n",
        "> Nguồn ảnh: [https://kpzhang93.github.io/MTCNN_face_detection_alignment/](https://kpzhang93.github.io/MTCNN_face_detection_alignment/)"
      ],
      "id": "1cYJ9VOhEWsN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thTAY4eKEWsR"
      },
      "source": [
        "**Link to [Try step by step](try_mtcnn_step_by_step.ipynb)**"
      ],
      "id": "thTAY4eKEWsR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtp3-7RJEWsP"
      },
      "source": [
        "---\n",
        "# 2. Cài đặt tuần tự\n",
        "\n",
        "\n"
      ],
      "id": "gtp3-7RJEWsP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ARjnzFMPrSf"
      },
      "source": [
        "Training data:\n",
        "- Nhóm sự dụng network được train sẵn trên bộ dữ liệu WIDER FACE bao gồm 32,203 images và label 393,703 faces.\n",
        "- Bộ dữ liệu được chia thành các tập training, validation, testing với tỉ lệ 40%/10%/50%."
      ],
      "id": "1ARjnzFMPrSf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjHBhYpGEWZo"
      },
      "source": [
        "### Thiết kế\n",
        "![index](https://kpzhang93.github.io/MTCNN_face_detection_alignment/support/index.png)\n",
        "> Nguồn ảnh: [https://kpzhang93.github.io/MTCNN_face_detection_alignment/](https://kpzhang93.github.io/MTCNN_face_detection_alignment/)\n",
        "\n",
        "\n"
      ],
      "id": "BjHBhYpGEWZo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FlsrdwqExRq"
      },
      "source": [
        "#### The Three Stages of MTCNN:\n",
        "Bước đầu tiên là lấy hình ảnh và thay đổi kích thước theo các tỷ lệ khác nhau để xây dựng một kim tự tháp hình ảnh, đây là đầu vào của **three-staged cascaded network**.\n",
        "\n",
        "> **?? Tại sao chúng ta lại tạo ra một image pyramid**\n",
        "> Bằng cách tăng tính đa dạng của dữ liệu, độ chính xác của mô hình MTCNN được nâng cao.\n",
        "\n",
        "![inputimage](https://drive.google.com/file/d/14xhPMlsoKbKAcGu5jn4dkvOewfYtFY4o/view)\n",
        "> Input image is resized to different scales to build an image pyramid"
      ],
      "id": "2FlsrdwqExRq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx5i133iEf5U"
      },
      "source": [
        "##### Stage 1: The Proposal Network (P-Net)\n",
        "\n",
        "![P-net](/content/P-net.jpeg)\n",
        "> P-Net (from MTCNN paper)\n",
        "\n",
        "**P-net** là một Fully convolutional network (FCN), **P-net** được sử dụng để lấy các cửa sổ ứng viên và các vector hồi quy bao quanh. Sự khác biết giữa FCN và CNN đó là FCN không sử dụng dense layer.\n",
        "\n",
        "Bounding box regression là công nghệ phổ biến để dự đoán khu vực của một đối tượng phân lớp, trong trường hợp này là khuôn mặt.\n",
        "\n",
        "After that, we employ non-maximum suppression (NMS) to merge highly overlapped candidates.\n",
        "\n",
        "**Input:** image RGB\n",
        "\n",
        "**Output:** danh sách n-box vector (1x9)\n",
        "***\n"
      ],
      "id": "wx5i133iEf5U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU4dQTI0Eka8"
      },
      "source": [
        "##### Stage 2: The Refine Network (R-Net)\n",
        "\n",
        "![R-net](R-net.jpeg)\n",
        "> R-Net (from MTCNN paper)\n",
        "\n",
        "Tất cả các ứng viên từ P-net sẽ được đưa vào R-net. R-net là một CNN bởi vì có một dense layer ở cuối stage. R-net giảm thêm số lượng ứng viên, thực hiện calibration các bounding box regression và NMS (non-maximum suppression) để hợp nhất các ứng viên trùng lắp.\n",
        "\n",
        "**Input:** output của P-net\n",
        "\n",
        "**Output:** Có phải là khuôn mặt hay không, một vector có 4 phần tử là bounding box của khuôn mặt, một vector 10 phần tử là các vị trí trong khuôn mặt.\n",
        "***\n",
        "\n"
      ],
      "id": "EU4dQTI0Eka8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v94zdTZ0Emzu"
      },
      "source": [
        "##### Stage 3: The Output Network (O-Net)\n",
        "\n",
        "![O-net](O-net.jpeg)\n",
        "> R-Net (from MTCNN paper)\n",
        "\n",
        "Giai đoạn này tương tự như R-net, nhưng Output của network này mô tả chi tiết hơn về 5 điềm của khuông mặt mắt, mũi, miệng.\n",
        "\n",
        "**Input:** output của R-net\n",
        "\n",
        "**Output:** Vector có 4 phần tử là bounding box của khuôn mặt, một vector 5 phần tử các vị trí của khuôn mặt\n"
      ],
      "id": "v94zdTZ0Emzu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3NuU52xVF20"
      },
      "source": [
        "##Đánh giá: đang thực hiện\n",
        "***"
      ],
      "id": "T3NuU52xVF20"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swxP8IUnEWsT"
      },
      "source": [
        "---\n",
        "# 3. Cài đặt song song (trên GPU)"
      ],
      "id": "swxP8IUnEWsT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4LSQrmqEWsU"
      },
      "source": [
        "---\n",
        "# 4. Cài đặt song song (trên GPU) + tối ưu hóa"
      ],
      "id": "n4LSQrmqEWsU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI0Bxv-fEWsU"
      },
      "source": [
        "---\n",
        "# 5. Nhìn lại quá trình làm đồ án"
      ],
      "id": "SI0Bxv-fEWsU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LelOXVg5DMJG"
      },
      "source": [
        ""
      ],
      "id": "LelOXVg5DMJG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iIjHz3zCbay"
      },
      "source": [
        "---\n",
        "#6. Phụ lục tham khảo"
      ],
      "id": "7iIjHz3zCbay"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvB6pBMICZzA"
      },
      "source": [
        "## The Three Tasks of MTCNN:\n",
        "Trong tất cả các stage của Networks đều thực hiện 3 task: face/non-face classification, bounding box regression, facial landmark localization.\n",
        "\n",
        "### 1. Face classification:\n",
        "Sử dụng cross-entropy loss vì đây là bài toán phân 2 lớp, với mỗi mẫu $x_i$\n",
        "\n",
        "$$L_i^{det} = -(y_i^{det}\\log(p_i) + (1 - y_i^{det})(1-\\log(p_i)))$$\n",
        "\n",
        "Trong đó, $p_i$ là xác xuất được tạo ra bớt net chỉ ra một sample là face. $y_i^{det} \\in {0, 1}$ là giá trị thật khuôn mặt hoặc không.\n",
        "\n",
        "### 2. Bounding box regression:\n",
        "Với mỗi cửa sổ ứng viên, chúng ta dự đoán các vị trí tin tưởng tạo nên một bộ offset (left top, height, width). Việc huấn luyện là bài toán regression cho nên sử dụng Euclidean loss cho mỗi sameple $x_i$:\n",
        "\n",
        "$$L_i^{box} = \\parallel\\widehat{y}_i^{box} - y_i^{box}\\parallel_2^2$$\n",
        "\n",
        "Trong đó, $\\widehat{y}_i^{box}$ là các vị trí dự đoán được của net, $y_i^{box}$ là tọa độ thật. Chúng ta sẽ có bốn góc, bao gồm left top, height, width và $y_i^{box} \\in R^4$\n",
        "\n",
        "### 3. Facial Landmark localization:\n",
        "Tương tự như bài toán regression và chúng ta sẽ đi minimize Euclidean distance:\n",
        "\n",
        "$$L_i^{landmark} = \\parallel\\widehat{y}_i^{landmark} - y_i^{landmark}\\parallel_2^2$$"
      ],
      "id": "cvB6pBMICZzA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKq1RiQIEWsS"
      },
      "source": [
        "## Evaluate accuracy of models\n",
        "#### Evaluation on face detection\n",
        "\n",
        "Để đánh giá tính đúng đắn của mô hình, nhóm của tác giả đã so sánh với các phương pháp khác trong SOTA ()[] trên bộ dự liệu phát hiện khuôn mặt và điểm chuẩn FDDB [25], WINDER FACE [24], và dấu mốc trên khuôn mặt được chú thích trong điểm chuẩn AFLW:\n",
        "    - Tập dữ liệu FDDB chứa các chú thích cho 5.171 khuôn mặt trong một tập hợp gồm 2.845 hình ảnh.\n",
        "    - Bộ dữ liệu WIDER FACE bao gồm 393.703 hộp giới hạn khuôn mặt được gắn nhãn trong 32.203 hình ảnh trong đó 50% trong số đó để thử nghiệm (chia thành ba tập con theo độ khó của hình ảnh), 40% dành cho đào tạo và phần còn lại để xác thực.\n",
        "    - AFLW chứa chú thích các mốc khuôn mặt cho 24.386 khuôn mặt và chúng tôi sử dụng cùng một tập hợp con thử nghiệm.\n",
        "\n",
        "![Evaluation](./images/evaluation.png)\n",
        "\n",
        "#### Evaluation on face alignment \n",
        "\n",
        "Nhóm tác giả so sánh performance với các phương pháp RCPR, TSPM, Luxand face SDK, ESR, CDM, SDM, và TCDCN. Sai số trung bình được đo bằng khoảng cách giữa các điểm mốc ước tính và độ chân thực trên mặt đất, và được chuẩn hóa đối với khoảng cách giữa hai mắt.\n",
        "\n",
        "![Alignment](./images/alignment.png)"
      ],
      "id": "OKq1RiQIEWsS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZWxcWD3EWsS"
      },
      "source": [
        "## Improvements with previous CNN\n",
        "\n",
        "Nhiều CNN đã được thiết kế để nhận diện khuôn mặt. Tuy nhiên, nhóm tác giả nhận thấy rằng hiệu suất của nó có thể bị hạn chế bởi các sự kiện sau:\n",
        "    - Một số bộ lọc trong các lớp tích chập thiếu tính đa dạng có thể hạn chế khả năng phân biệt của chúng.\n",
        "    - So với các nhiệm vụ phân loại và phát hiện phản đối nhiều lớp khác, phát hiện khuôn mặt là một nhiệm vụ phân loại nhị phân đầy thách thức, do đó, nó có thể cần số lượng bộ lọc trên mỗi lớp ít hơn.\n",
        "Để làm được điều này, nhóm tác giả giảm số lượng bộ lọc và thay đổi bộ lọc 5 × 5 thành bộ lọc 3 × 3 để giảm tính toán đồng thời tăng độ sâu để có được hiệu suất tốt hơn. Với những cải tiến này, so với kiến ​​trúc trước đó, có thể có được hiệu suất tốt hơn với thời gian chạy ít hơn.\n",
        "\n",
        "![comparisionspeed](./images/comparisionspeed.png)"
      ],
      "id": "9ZWxcWD3EWsS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSP5hJoLEWsU"
      },
      "source": [
        "---\n",
        "# 7. Tài liệu tham khảo\n",
        "\n",
        "- [x] [PDF report](https://arxiv.org/pdf/1604.02878.pdf)\n",
        "- [x] [Document Guide](https://medium.com/@iselagradilla94/multi-task-cascaded-convolutional-networks-mtcnn-for-face-detection-and-facial-landmark-alignment-7c21e8007923)\n",
        "- [x] [MTCNN-Pytorch](https://github.com/TropComplique/mtcnn-pytorch)"
      ],
      "id": "WSP5hJoLEWsU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKiO93L__IC5"
      },
      "source": [
        ""
      ],
      "id": "xKiO93L__IC5",
      "execution_count": null,
      "outputs": []
    }
  ]
}