{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue; text-align: center;\">Multi-task Cascaded Convolutional Networks (MTCNN) for Face Detection and Facial Landmark Alignment Using Parallel</h1>\n",
    "\n",
    "---\n",
    "\n",
    "<h2 style=\"color: gray; text-align: right;\">Members of Team:</h2>\n",
    "\n",
    "| MSSV | Full Name | ID Github |\n",
    "| ---- | ---- | -------- |\n",
    "| 1612835 | Bùi Trọng Xuyến | btxuyenhcmus |\n",
    "| 1612165 | Nguyễn Đào Vinh Hải | NDVHaiHCMUS |\n",
    "| 1612859 | Nguyễn Đình Hữu | NguyenDinhHuu-HCMUS |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.  Mô tả ứng dụng\n",
    "\n",
    "**Input:** Một tấm ảnh RGB hoặc một video live trực tiếp.\n",
    "\n",
    "**Output:** Một tấm ảnh RGB hoặc một video live trực tiếp được bounding các object và gắn nhãn.\n",
    "\n",
    "**Ý nghĩa thực tế của ứng dụng:**\n",
    "- bài toán face detection là một bài toán mang lại rất nhiều lợi ích hiện nay, từ việc quản lý con người, phát hiện đối tượng lạ, hay như chấm công,...\n",
    "- Khi chúng ta song song hoá được bài toán này thì sẽ đem lại lợi ích cao từ việc giảm chi phí tiền máy chủ, cho đến tiếp kiệm được thời gian.\n",
    "\n",
    "**ứng dụng này cần được tăng tốc**\n",
    "- Thời gian training của các mô hình neural hầu như đều rất chậm.\n",
    "- Khi xử lý với video khi lượng frame đưa xuống quá nhanh, kết quả trả về của mô hình không kiệp đáp ứng tạo nên độ trễ.\n",
    "- Bài toán sử dụng convolution là chủ yếu.\n",
    "- Xử lý nhiều trên matrix\n",
    "\n",
    "\n",
    "![index](./images/examples.png)\n",
    "> Nguồn ảnh: [https://kpzhang93.github.io/MTCNN_face_detection_alignment/](https://kpzhang93.github.io/MTCNN_face_detection_alignment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Cài đặt tuần tự\n",
    "### Ý tưởng\n",
    "![index](./images/index.png)\n",
    "\n",
    "### The Three Stages of MTCNN:\n",
    "Bước đầu tiên là lấy hình ảnh và thay đổi kích thước theo các tỷ lệ khác nhau để xây dựng một kim tự tháp hình ảnh, đây là đầu vào của **three-staged cascaded network**.\n",
    "\n",
    "> **?? Tại sao chúng ta lại tạo ra một image pyramid**\n",
    "> Bằng cách tăng tính đa dạng của dữ liệu, độ chính xác của mô hình MTCNN được nâng cao.\n",
    "\n",
    "![inputimage](./images/inputimage.png)\n",
    "> Input image is resized to different scales to build an image pyramid\n",
    "\n",
    "#### Stage 1: The Proposal Network (P-Net)\n",
    "\n",
    "![P-net](./images/P-net.jpeg)\n",
    "> P-Net (from MTCNN paper)\n",
    "\n",
    "P-net là một Fully convolutional network (FCN). Sự khác biết giữa FCN và CNN đó là FCN không sử dụng dense layer. P-net được sử dụng để lấy các cửa sổ ứng viên và các vector hồi quy bao quanh.\n",
    "\n",
    "Bounding box regression là công nghệ phổ biến để dự đoán khu vực của một đối tượng phân lớp, trong trường hợp này là khuôn mặt. Sau khi có tất cả các bounding box thì các bounding box này có thể bị chồng chéo lẫn nhau, cần thông qua một lớp lọc để cho ra khác khu vực không bị trùng lắp.\n",
    "\n",
    "**Input:** image RGB\n",
    "\n",
    "**Output:** danh sách n-box vector (1x9)\n",
    "***\n",
    "#### Stage 2: The Refine Network (R-Net)\n",
    "\n",
    "![R-net](./images/R-net.jpeg)\n",
    "> R-Net (from MTCNN paper)\n",
    "\n",
    "Tất cả các ứng viên từ P-net sẽ được đưa vào R-net. R-net là một CNN bởi vì có một dense layer ở cuối stage. R-net giảm thêm số lượng ứng viên, thực hiện calibration các bounding box regression và NMS (non-maximum suppression) để hợp nhất các ứng viên trùng lắp.\n",
    "\n",
    "**Input:** output cura P-net\n",
    "\n",
    "**Output:** Có phải là khuôn mặt hay không, một vector có 4 phần tử là bounding box của khuôn mặt, một vector 10 phần tử là các vị trí trong khuôn mặt.\n",
    "***\n",
    "#### Stage 3: The Output Network (O-Net)\n",
    "\n",
    "![O-net](./images/O-net.jpeg)\n",
    "> R-Net (from MTCNN paper)\n",
    "\n",
    "Giai đoạn này tương tự như R-net, nhưng Output của network này mô tả chi tiết hơn về 5 điềm của khuông mặt mắt, mũi, miệng.\n",
    "\n",
    "**Input:** output của R-net\n",
    "\n",
    "**Output:** Vector có 4 phần tử là bounding box của khuôn mặt, một vector 5 phần tử các vị trí của khuôn mặt\n",
    "***\n",
    "### The Three Tasks of MTCNN:\n",
    "Trong tất cả các stage của Networks đều thực hiện 3 task: face/non-face classification, bounding box regression, facial landmark localization.\n",
    "\n",
    "#### 1. Face classification:\n",
    "Sử dụng cross-entropy loss vì đây là bài toán phân 2 lớp, với mỗi mẫu $x_i$\n",
    "\n",
    "$$L_i^{det} = -(y_i^{det}\\log(p_i) + (1 - y_i^{det})(1-\\log(p_i)))$$\n",
    "\n",
    "Trong đó, $p_i$ là xác xuất được tạo ra bớt net chỉ ra một sample là face. $y_i^{det} \\in {0, 1}$ là giá trị thật khuôn mặt hoặc không.\n",
    "\n",
    "#### 2. Bounding box regression:\n",
    "Với mỗi cửa sổ ứng viên, chúng ta dự đoán các vị trí tin tưởng tạo nên một bộ offset (left top, height, width). Việc huấn luyện là bài toán regression cho nên sử dụng Euclidean loss cho mỗi sameple $x_i$:\n",
    "\n",
    "$$L_i^{box} = \\parallel\\widehat{y}_i^{box} - y_i^{box}\\parallel_2^2$$\n",
    "\n",
    "Trong đó, $\\widehat{y}_i^{box}$ là các vị trí dự đoán được của net, $y_i^{box}$ là tọa độ thật. Chúng ta sẽ có bốn góc, bao gồm left top, height, width và $y_i^{box} \\in R^4$\n",
    "\n",
    "#### 3. Facial Landmark localization:\n",
    "Tương tự như bài toán regression và chúng ta sẽ đi minimize Euclidean distance:\n",
    "\n",
    "$$L_i^{landmark} = \\parallel\\widehat{y}_i^{landmark} - y_i^{landmark}\\parallel_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Cài đặt song song (trên GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. Cài đặt song song (trên GPU) + tối ưu hóa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5. Nhìn lại quá trình làm đồ án"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. Tài liệu tham khảo\n",
    "\n",
    "- [x] [PDF report](https://arxiv.org/pdf/1604.02878.pdf)\n",
    "- [x] [Document Guide](https://medium.com/@iselagradilla94/multi-task-cascaded-convolutional-networks-mtcnn-for-face-detection-and-facial-landmark-alignment-7c21e8007923)\n",
    "- [x] [MTCNN-Pytorch](https://github.com/TropComplique/mtcnn-pytorch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
