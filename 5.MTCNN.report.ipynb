{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue; text-align: center;\">Multi-task Cascaded Convolutional Networks (MTCNN) for Face Detection and Facial Landmark Alignment Using Parallel</h1>\n",
    "\n",
    "---\n",
    "\n",
    "<h2 style=\"color: gray; text-align: right;\">Members of Team:</h2>\n",
    "\n",
    "| MSSV | Full Name | ID Github |\n",
    "| ---- | ---- | -------- |\n",
    "| 1612835 | Bùi Trọng Xuyến | btxuyenhcmus |\n",
    "| 1612165 | Nguyễn Đào Vinh Hải | NDVHaiHCMUS |\n",
    "| 1612859 | Nguyễn Đình Hữu | NguyenDinhHuu-HCMUS |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.  Mô tả ứng dụng\n",
    "\n",
    "**Input:** Một tấm ảnh RGB hoặc một video live trực tiếp.\n",
    "\n",
    "**Output:** Một tấm ảnh RGB hoặc một video live trực tiếp được bounding các object và gắn nhãn.\n",
    "\n",
    "**Ý nghĩa thực tế của ứng dụng:**\n",
    "- Bài toán face detection là một bài toán mang lại rất nhiều lợi ích hiện nay, từ việc quản lý con người, phát hiện đối tượng lạ, hay như chấm công,...\n",
    "- Khi chúng ta song song hoá được bài toán này thì sẽ đem lại lợi ích cao từ việc giảm chi phí tiền máy chủ, cho đến tiếp kiệm được thời gian.\n",
    "\n",
    "**Ứng dụng này cần được tăng tốc**\n",
    "- Khi xử lý với video khi lượng frame đưa xuống quá nhanh, kết quả trả về của mô hình không kịp đáp ứng tạo nên độ trễ.\n",
    "\n",
    "**Tiềm năng song song hóa**\n",
    "- Bài toán sử dụng convolution là chủ yếu.\n",
    "- Xử lý nhiều trên matrix\n",
    "\n",
    "\n",
    "![index](./images/examples.png)\n",
    "> Nguồn ảnh: [https://kpzhang93.github.io/MTCNN_face_detection_alignment/](https://kpzhang93.github.io/MTCNN_face_detection_alignment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Cài đặt tuần tự"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Ý tưởng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Với mỗi bức ảnh chúng ta sẽ cho qua mạng neural MTCNN đã được train trước sau đó sẽ cho ra kết quả bức ảnh với các bounding box có chứa khuôn mặt.\n",
    "\n",
    "* Từ việc xử lí trên từng bức ảnh nhóm sẽ phát triển lên phát hiện khuôn mặt trên video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data:\n",
    "- Nhóm sự dụng network được train sẵn trên bộ dữ liệu WIDER FACE bao gồm 32,203 images và label 393,703 faces.\n",
    "- Bộ dữ liệu được chia thành các tập training, validation, testing với tỉ lệ 40% / 10% / 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Các bước thực hiện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. Sơ đồ thực hiện nhận diện khuôn mặt trong MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![inputimage](./images/1.png)\n",
    "> Nguồn ảnh: [https://manutdzou.github.io/2017/01/24/mtcnn.html](https://manutdzou.github.io/2017/01/24/mtcnn.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Các bước thực hiện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* B1: Cho ảnh đầu vào image pyramid với nhiều kích cỡ khác nhau. (Từ ảnh gốc cho ảnh down scale thành 10 bức ảnh có kích thước nhỏ hơn).\n",
    "\n",
    "* B2: Input của bước này các bức ảnh đã được pyramid image. Ở bước này P-Net có nhiệm vụ là xác nhận các windows có chứa khuôn mặt nhanh nhưng thiếu chính xác. Sau khi có các bounding box ở P-Net chúng ta sẽ dùng NMS và bounding box regression để giảm số lượng của các bounding box đã được dự đoán ở P-Net. Sau cùng ta có được output là các face classification và bounding box regression.\n",
    "\n",
    "![p-net](./images/pnet.png)\n",
    "> Nguồn ảnh: [https://www.pytorials.com/face-detection-matching-using-facenet/](https://www.pytorials.com/face-detection-matching-using-facenet/)\n",
    "\n",
    "* B3: Input của bước này là các output bounding box của B2. Ở đây thì R-Net có độ sâu về cấu trúc so với P-Net. Nhiệm vụ chính của R-Net là lọc các bounding box của P-Net + NMS + bounding box regression. Cũng như P-Net sau khi lọc các bounding box ở R-Net thì chúng ta cho qua NMS và bounding box regression để giảm số lượng của các bounding box đã được dự đoán. Ouput ở bước này các face classification và bounding box regression.\n",
    "\n",
    "![r-net](./images/rnet.png)\n",
    "> Nguồn ảnh: [https://www.pytorials.com/face-detection-matching-using-facenet/](https://www.pytorials.com/face-detection-matching-using-facenet/)\n",
    "\n",
    "* B4: Input ở bước này là các output bounding box của B3. Tương tự như R-Net, nhiệm vụ chính của O-Net là lọc các bounding box. Sau cùng NMS và bounding box regression có nhiệm vụ lọc lại bounding box chính xác và đánh dấu các vị trí trên khuôn mặt được phát hiện. \n",
    "\n",
    "![o-net](./images/onet.png)\n",
    "> Nguồn ảnh: [https://www.pytorials.com/face-detection-matching-using-facenet/](https://www.pytorials.com/face-detection-matching-using-facenet/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Đánh giá code tuần tự"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Cài đặt song song (trên GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. Cài đặt song song (trên GPU) + tối ưu hóa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5. Nhìn lại quá trình làm đồ án"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. Tài liệu tham khảo\n",
    "\n",
    "- [x] [PDF report](https://arxiv.org/pdf/1604.02878.pdf)\n",
    "- [x] [Document Guide](https://medium.com/@iselagradilla94/multi-task-cascaded-convolutional-networks-mtcnn-for-face-detection-and-facial-landmark-alignment-7c21e8007923)\n",
    "- [x] [MTCNN-Pytorch](https://github.com/TropComplique/mtcnn-pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phục lục"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### PL.1. The Three Stages of MTCNN:\n",
    "\n",
    "##### PL.1.1. Stage 1: The Proposal Network (P-Net)\n",
    "\n",
    "![P-net](./images/P-net.jpeg)\n",
    "> P-Net (from MTCNN paper)\n",
    "\n",
    "* P-net là một Fully convolutional network (FCN). Sự khác biết giữa FCN và CNN đó là FCN không sử dụng dense layer. P-net được sử dụng để lấy các cửa sổ ứng viên và các vector hồi quy bao quanh.\n",
    "\n",
    "* Bounding box regression là công nghệ phổ biến để dự đoán khu vực của một đối tượng phân lớp, trong trường hợp này là khuôn mặt. Sau khi có tất cả các bounding box thì các bounding box này có thể bị chồng chéo lẫn nhau, cần thông qua một lớp lọc để cho ra khác khu vực không bị trùng lắp.\n",
    "\n",
    "\n",
    "##### PL.1.2. Stage 2: The Refine Network (R-Net)\n",
    "\n",
    "![R-net](./images/R-net.jpeg)\n",
    "> R-Net (from MTCNN paper)\n",
    "\n",
    "* Tất cả các ứng viên từ P-net sẽ được đưa vào R-net. R-net là một CNN bởi vì có một dense layer ở cuối stage. R-net giảm thêm số lượng ứng viên, thực hiện calibration các bounding box regression và NMS (non-maximum suppression) để hợp nhất các ứng viên trùng lắp.\n",
    "\n",
    "\n",
    "\n",
    "##### PL.1.3. Stage 3: The Output Network (O-Net)\n",
    "\n",
    "![O-net](./images/O-net.jpeg)\n",
    "> R-Net (from MTCNN paper)\n",
    "\n",
    "* Giai đoạn này tương tự như R-net, nhưng Output của network này mô tả chi tiết hơn về 5 điềm của khuông mặt mắt, mũi, miệng.\n",
    "\n",
    "\n",
    "#### PL.2. The Three Tasks of MTCNN:\n",
    "\n",
    "Trong tất cả các stage của Networks đều thực hiện 3 task: face/non-face classification, bounding box regression, facial landmark localization.\n",
    "\n",
    "##### PL.2.1. Face classification:\n",
    "* Sử dụng cross-entropy loss vì đây là bài toán phân 2 lớp, với mỗi mẫu $x_i$\n",
    "\n",
    "$$L_i^{det} = -(y_i^{det}\\log(p_i) + (1 - y_i^{det})(1-\\log(p_i)))$$\n",
    "\n",
    "*Trong đó, $p_i$ là xác xuất được tạo ra bớt net chỉ ra một sample là face. $y_i^{det} \\in {0, 1}$ là giá trị thật khuôn mặt hoặc không.\n",
    "\n",
    "##### PL.2.2. Bounding box regression:\n",
    "Với mỗi cửa sổ ứng viên, chúng ta dự đoán các vị trí tin tưởng tạo nên một bộ offset (left top, height, width). Việc huấn luyện là bài toán regression cho nên sử dụng Euclidean loss cho mỗi sameple $x_i$:\n",
    "\n",
    "$$L_i^{box} = \\parallel\\widehat{y}_i^{box} - y_i^{box}\\parallel_2^2$$\n",
    "\n",
    "Trong đó, $\\widehat{y}_i^{box}$ là các vị trí dự đoán được của net, $y_i^{box}$ là tọa độ thật. Chúng ta sẽ có bốn góc, bao gồm left top, height, width và $y_i^{box} \\in R^4$\n",
    "\n",
    "##### PL.2.3. Facial Landmark localization:\n",
    "Tương tự như bài toán regression và chúng ta sẽ đi minimize Euclidean distance:\n",
    "\n",
    "$$L_i^{landmark} = \\parallel\\widehat{y}_i^{landmark} - y_i^{landmark}\\parallel_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trả lời issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tại sao phải có 3 stage ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vai trò của R-Net "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
