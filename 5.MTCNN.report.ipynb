{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f26283",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "<h1 style=\"color: blue; text-align: center;\">Multi-task Cascaded Convolutional Networks (MTCNN) for Face Detection and Facial Landmark Alignment Using Parallel</h1>\n",
    "\n",
    "---\n",
    "\n",
    "<h2 style=\"color: gray; text-align: right;\">Members of Team:</h2>\n",
    "\n",
    "| MSSV | Full Name | ID Github |\n",
    "| ---- | ---- | -------- |\n",
    "| 1612835 | Bùi Trọng Xuyến | btxuyenhcmus |\n",
    "| 1612165 | Nguyễn Đào Vinh Hải | NDVHaiHCMUS |\n",
    "| 1612859 | Nguyễn Đình Hữu | NguyenDinhHuu-HCMUS |\n",
    "\n",
    "\n",
    "https://github.com/btxuyenHCMUS/MTCNN-GPU.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076f66d",
   "metadata": {},
   "source": [
    "---\n",
    "## Mô tả ứng dụng\n",
    "\n",
    "**Input:** Một tấm ảnh RGB, Video, Video livestream.\n",
    "\n",
    "**Output:** Một tấm ảnh RGB hoặc một video live trực tiếp được bounding các khuôn mặt và đánh dấu các vị trí trên khuôn mặt.\n",
    "\n",
    "### Ý nghĩa thực tế của ứng dụng:\n",
    "- Bài toán face detection là một bài toán mang lại rất nhiều lợi ích hiện nay: auto focus đối tượng trên máy ảnh, camera giám sát, smart house, tự động phát hiện khuôn mặt để tag trong các mạng xã hội, bước đầu cho bài toán face reccorgnition,...\n",
    "\n",
    "\n",
    "### Ứng dụng này cần được tăng tốc\n",
    "- Khi xử lý với video lượng frame đưa xuống quá nhanh, kết quả trả về của mô hình không kịp đáp ứng tạo xử lí nên có độ trễ nhất định.\n",
    "- Khi chúng ta song song hoá được bài toán này thì sẽ đem lại lợi ích lớn từ việc tiếp kiệm được thời gian.\n",
    "\n",
    "### Tiềm năng song song hóa\n",
    "- Song song hóa các phép tích chập trong mô hình (tức là các phép nhân ma trận với nhau).\n",
    "\n",
    "\n",
    "![index](./images/examples.png)\n",
    "> Nguồn ảnh: [https://kpzhang93.github.io/MTCNN_face_detection_alignment/](https://kpzhang93.github.io/MTCNN_face_detection_alignment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea1a70f",
   "metadata": {},
   "source": [
    "---\n",
    "## Cài đặt tuần tự"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef9396",
   "metadata": {},
   "source": [
    "### Ý tưởng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d7587",
   "metadata": {},
   "source": [
    "* Các phương pháp xử lý ảnh truyền thống tích chập để rút trích đặt trưng cho việc chọn lọc ra hình ảnh có chứa khuôn mặt. Sử dụng mạng học sâu để huấn luuện các mạng neural cho ra tập các tham số huấn luyện linh động hơn việc đưa ra các tham số cho từng bài toán rút trích đặc trưng cụ thể.\n",
    "* Thay vì xử lý tất cả các công việc trong cùng một mạng như vgg-16,RCNN,CNN,.. thì trong MTCNN chia ra làm ba giai đoạn thực hiện với những nhiệm vụ khác nhau để cho ra kết quả. Trong đó kết quả của giai đoạn trước sẽ là đầu vào của giai đoạn sau.\n",
    "* Từ việc xử lí trên từng bức ảnh, nhóm sẽ phát triển lên phát hiện khuôn mặt trên video hoặc video livestream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77853ef2",
   "metadata": {},
   "source": [
    "**Training data:**\n",
    "- Nhóm sử dụng network được train sẵn trên bộ dữ liệu WIDER FACE bao gồm 32,203 images và label 393,703 faces.\n",
    "- Bộ dữ liệu được chia thành các tập training, validation, testing với tỉ lệ 40% / 10% / 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0ac13",
   "metadata": {},
   "source": [
    "**Đánh giá tính đúng đắn của mô hình**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f039fc0d",
   "metadata": {},
   "source": [
    "Để đánh giá tính đúng đắn của mô hình, nhóm của tác giả đã so sánh với các phương pháp khác trong SOTA trên bộ dữ liệu phát hiện khuôn mặt và điểm chuẩn FDDB, WIDER FACE, và dấu mốc trên khuôn mặt được chú thích trong điểm chuẩn AFLW:\n",
    "\n",
    "- Tập dữ liệu FDDB chứa các chú thích cho 5.171 khuôn mặt trong một tập hợp gồm 2.845 hình ảnh.\n",
    "- Bộ dữ liệu WIDER FACE bao gồm 393.703 hộp giới hạn khuôn mặt được gắn nhãn trong 32.203 hình ảnh trong đó 50% trong số đó để thử nghiệm (chia thành ba tập con theo độ khó của hình ảnh), 40% dành cho đào tạo và phần còn lại để xác thực.\n",
    "- AFLW chứa chú thích các mốc khuôn mặt cho 24.386 khuôn mặt và sử dụng cùng một tập hợp con thử nghiệm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97558a64",
   "metadata": {},
   "source": [
    "\n",
    "![Evaluation](./images/evaluation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b3136",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Evaluation on face alignment**\n",
    "\n",
    "Nhóm tác giả so sánh performance với các phương pháp RCPR, TSPM, Luxand face SDK, ESR, CDM, SDM, và TCDCN. Sai số trung bình được đo bằng khoảng cách giữa các các bounding box ước tính và ground truth của bounding box, và được chuẩn hóa đối với khoảng cách giữa hai mắt.\n",
    "\n",
    "![Alignment](./images/alignment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646e6ff7",
   "metadata": {},
   "source": [
    "### Các bước thực hiện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8f06f8",
   "metadata": {},
   "source": [
    "#### Sơ đồ thực hiện nhận diện khuôn mặt trong MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531488e",
   "metadata": {},
   "source": [
    "![inputimage](./images/1.png)\n",
    "> Nguồn ảnh: [https://manutdzou.github.io/2017/01/24/mtcnn.html](https://manutdzou.github.io/2017/01/24/mtcnn.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21216244",
   "metadata": {},
   "source": [
    "#### Các bước thực hiện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e18047",
   "metadata": {},
   "source": [
    "* B1: Cho ảnh đầu vào image pyramid với nhiều kích cỡ khác nhau. (Từ ảnh gốc cho ảnh down scale thành 10 bức ảnh có kích thước nhỏ hơn).\n",
    "\n",
    "* B2: Input của bước này các bức ảnh đã được xử lí ở pyramid image. Ở trong giai đoạn này P-Net có nhiệm vụ là xác nhận các windows có chứa khuôn mặt nhanh nhưng thiếu chính xác. Sau khi có các bounding box ở P-Net chúng ta sẽ dùng NMS và bounding box regression để giảm số lượng của các bounding box đã được dự đoán ở P-Net. Sau cùng ta có được output là các bounding box và bounding box regression.\n",
    "\n",
    "![p-net](./images/pnet.png)\n",
    "> Nguồn ảnh: [https://www.pytorials.com/face-detection-matching-using-facenet/](https://www.pytorials.com/face-detection-matching-using-facenet/)\n",
    "\n",
    "* B3: Input của bước này là các output bounding box của B2. Ở đây thì R-Net có độ sâu về cấu trúc so với P-Net. Nhiệm vụ chính của R-Net là lọc các bounding box của P-Net + NMS + bounding box regression. Cũng như P-Net sau khi lọc các bounding box ở R-Net thì chúng ta cho qua NMS và bounding box regression để giảm số lượng của các bounding box đã được dự đoán. Ouput ở bước này các bounding box và bounding box regression.\n",
    "\n",
    "![r-net](./images/rnet.png)\n",
    "> Nguồn ảnh: [https://www.pytorials.com/face-detection-matching-using-facenet/](https://www.pytorials.com/face-detection-matching-using-facenet/)\n",
    "\n",
    "* B4: Input ở bước này là các output bounding box của B3. Tương tự như R-Net, nhiệm vụ chính của O-Net là lọc các bounding box. Sau cùng NMS và bounding box regression có nhiệm vụ lọc lại bounding box chính xác và đánh dấu các vị trí trên khuôn mặt được phát hiện. \n",
    "\n",
    "![o-net](./images/onet.png)\n",
    "> Nguồn ảnh: [https://www.pytorials.com/face-detection-matching-using-facenet/](https://www.pytorials.com/face-detection-matching-using-facenet/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bba90e4",
   "metadata": {},
   "source": [
    "### Đánh giá code tuần tự"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee377b8",
   "metadata": {},
   "source": [
    "#### Đánh giá code tuần tự "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1439b",
   "metadata": {},
   "source": [
    "Dưới đây là công thức tính ma trận output của hàm convolution 2d trong pytorch. Nhóm đã dựa vào công thức để viết lại hàm convolution sau đó import vào folder torch. Từ việc, viết hoàn thành hàm convolution, tiếp theo dùng function jit của cuda để chạy chương trình. Dưới đây là kết quả chạy chương trình với hàm convolution 2d với jit function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee077760",
   "metadata": {},
   "source": [
    "![con2d](./images/conv2d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413330e",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "###### Bảng đánh giá code tuần tự\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0034cc",
   "metadata": {},
   "source": [
    "Bảng đánh giá thời gian chạy trên ảnh family.jpeg có kích thước $600x400$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef2f80b",
   "metadata": {},
   "source": [
    "![family](./images/r-jit-family.png)\n",
    "> Ảnh: family.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61751136",
   "metadata": {},
   "source": [
    "| family.jpeg | P-Net | R-Net | O-Net |\n",
    "| --- | --- | --- | --- |\n",
    "| Thời gian chạy | 1460ms | 566ms | 606ms |\n",
    "| Số lượng bounding box | 192 | 36 | 23 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6543150",
   "metadata": {},
   "source": [
    "Bảng đánh giá thời gian chạy trên ảnh oscar1.jpg có kích thước $4646x1800$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f039f250",
   "metadata": {},
   "source": [
    "![oscar1](./images/r-jit-oscar.png)\n",
    "> Ảnh: oscar1.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3352c35",
   "metadata": {},
   "source": [
    "| oscar1.jpg | P-Net | R-Net | O-Net |\n",
    "| --- | --- | --- | --- |\n",
    "| Thời gian chạy | 34200ms | 202000ms | 45500ms |\n",
    "| Số lượng bounding box | 11081 | 1613 | 967 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9a67bd",
   "metadata": {},
   "source": [
    "Bảng đánh giá thời gian chạy trên ảnh test.jpg có kích thước $612x408$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c931ee3",
   "metadata": {},
   "source": [
    "![test](./images/r-jit-test.png)\n",
    "> Ảnh: test.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71df6a62",
   "metadata": {},
   "source": [
    "| test.jpg | P-Net | R-Net | O-Net |\n",
    "| --- | --- | --- | --- |\n",
    "| Thời gian chạy | 1510ms | 1580ms | 1450ms |\n",
    "| Số lượng bounding box | 529 | 80 | 53 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f7673",
   "metadata": {},
   "source": [
    "Bảng đánh giá thời gian chạy trên ảnh test2.jpg có kích thước $768x512$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e0825",
   "metadata": {},
   "source": [
    "![test](./images/r-jit-test2.png)\n",
    "> Ảnh: test2.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b73d3",
   "metadata": {},
   "source": [
    "| test2.jpg | P-Net | R-Net | O-Net |\n",
    "| --- | --- | --- | --- |\n",
    "| Thời gian chạy | 2240ms | 4140ms | 4059ms |\n",
    "| Số lượng bounding box | 1334 | 258 | 138 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4ea9c",
   "metadata": {},
   "source": [
    "---\n",
    "## Cài đặt song song (trên GPU)\n",
    "### Ý tưởng\n",
    "**Conv**\n",
    "\n",
    "- Dense Conv2d,trong mô hình xử dụng nhiều phép tích chập trên một khối họp nhân với nhau.\n",
    "\n",
    "- Mỗi thread sẽ đảm nhiệm việc tính toán 1 pixel của output.\n",
    "\n",
    "- Mỗi lớp trong dense sẽ do 1 stream quản lý."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4cdeb3",
   "metadata": {},
   "source": [
    "**Prelu**\n",
    "- Mỗi thread sẽ đảm nhiệm việc bật một pixel dựa vào input và weight.\n",
    "- Mỗi lớp trong input sẽ do 1 stream quản lý."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5c754",
   "metadata": {},
   "source": [
    "**MaxPool**\n",
    "- Mỗi thread sẽ đảm nhiệm việc tính toán giá trị một pixel\n",
    "- Mỗi lớp trong dense sẽ do 1 stream quản lý."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80908c0",
   "metadata": {},
   "source": [
    "### Các bước thực hiện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076890c6",
   "metadata": {},
   "source": [
    "Dưới đây là một ví dụ minh họa về khối convolution trong MTCNN pytorch\n",
    "\n",
    "![convolution](./images/conv.png)\n",
    "\n",
    "Thì theo như hình ở phía trên ta có thể thấy convolution layer gồm n lớp mỗi lớp có kích thước $HxW$. Do đó nhóm sẽ thực hiện chạy một vòng for để duyệt từng lớp convolution trong khối. Trong mỗi lớp convolution sẽ thực hiện song song hóa từng lớp.\n",
    "\n",
    "Trong từng lớp convolution sẽ thực hiện nhân hai ma trận trên GPU. Mỗi thread trong GPU sẽ xử lí một pixel đầu ra của từng lớp convolution và quá trình đó sẽ thực hiện cho đến khi duyệt hết các lớp convolution trong khối convolution. \n",
    "\n",
    "![matrix](./images/matrix.png)\n",
    "\n",
    "Song khi song song hóa được việc nhân hai ma trận trong từng lớp convolution, nhóm tiếp tục song song hóa được hàm kích hoạt PReLU và hàm maxpool2d theo công thức pytorch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aa08c4",
   "metadata": {},
   "source": [
    "### Đánh giá code song song"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c4d0b7",
   "metadata": {},
   "source": [
    "Sau khi thực hiện cuda.jit thì nhóm có một số đánh giá về kết quả như sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b706c401",
   "metadata": {},
   "source": [
    "Kết quả chạy trên ảnh family.jpeg có kích thước 600x400:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af29a25",
   "metadata": {},
   "source": [
    "> Kết quả ảnh chạy trên cuda.jit:\n",
    "![cuda](./images/cuda-family.png)\n",
    "* Thời gian chạy: 1.52 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d30927",
   "metadata": {},
   "source": [
    "Kết quả chạy trên ảnh test.jpg có kích thước 612x408:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa6dd5",
   "metadata": {},
   "source": [
    "![cuda-test](./images/cuda-test.png)\n",
    "* Thời gian chạy: 1.53 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bb62f0",
   "metadata": {},
   "source": [
    "Kết quả chạy trên ảnh test.jpg có kích thước 768x512:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657c20a2",
   "metadata": {},
   "source": [
    "![cuda-test2](./images/cuda-test2.png)\n",
    "* Thời gian chạy: 2.12 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7667d8c5",
   "metadata": {},
   "source": [
    "## Tối ưu hóa song song lần 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10acd3bd",
   "metadata": {},
   "source": [
    "### Ý Tưởng\n",
    "**Conv**\n",
    "- Sử dụng shared memory để lưu lại dữ liệu ở input và weight giúp việc tính toán nhanh hơn.\n",
    "\n",
    "**Prelu**\n",
    "- Vì việc bật pixel không được gọi lại nhiều lần nên kh cần áp dụng shared memory.\n",
    "\n",
    "**Maxpool**\n",
    "- Sử dụng shared memory để lưu lại dữ liệu ở input giúp việc tính toán nhanh hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f7e5ff",
   "metadata": {},
   "source": [
    "### Các bước thực hiện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61218c94",
   "metadata": {},
   "source": [
    "### Đánh giá tối ưu hóa lần 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a286caf",
   "metadata": {},
   "source": [
    "## Tối ưu hóa song song lần 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d86995",
   "metadata": {},
   "source": [
    "###  Ý tưởng\n",
    "- Cả conv, prelu, maxpool đều là dense nên có thể áp dụng streaming để các công việc có thể overlap với nhau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef21e11",
   "metadata": {},
   "source": [
    "### Các bước thực hiện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65cfc0f",
   "metadata": {},
   "source": [
    "### Đánh giá tối ưu hóa lần 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639c976",
   "metadata": {},
   "source": [
    "---\n",
    "## Nhìn lại quá trình làm đồ án"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d59e2a",
   "metadata": {},
   "source": [
    "### Những điều đạt được\n",
    "- Nâng cao thêm kiến thức về lập trình song song kế thừa từ môn học trước.\n",
    "- Học được cấu trúc cũng như mô hình thiết kế của một DNN.\n",
    "- Quản lý công việc, làm việc nhóm và quản lý source code một cách hiệu quả."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059d33b",
   "metadata": {},
   "source": [
    "### Những điều chưa đạt được\n",
    "- Chưa thực hiện được tối ưu hóa song song lần 1 và lần 2.\n",
    "- Quá trình làm việc nhóm đã có trục trặc khi các thành viên không liên kết với nhau.\n",
    "- Tình hình dịch covid ảnh hưởng đến workflow của nhóm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b656b3b",
   "metadata": {},
   "source": [
    "---\n",
    "## Tài liệu tham khảo\n",
    "\n",
    "- [x] [PDF report](https://arxiv.org/pdf/1604.02878.pdf)\n",
    "- [x] [Document Guide](https://medium.com/@iselagradilla94/multi-task-cascaded-convolutional-networks-mtcnn-for-face-detection-and-facial-landmark-alignment-7c21e8007923)\n",
    "- [x] [MTCNN-Pytorch](https://github.com/TropComplique/mtcnn-pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15f1f7",
   "metadata": {},
   "source": [
    "## Phục lục"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd744e9",
   "metadata": {},
   "source": [
    "**Improvements with previous CNN**\n",
    "\n",
    "Nhiều CNN đã được thiết kế để nhận diện khuôn mặt. Tuy nhiên, nhóm tác giả nhận thấy rằng hiệu suất của nó có thể bị hạn chế bởi các sự kiện sau:\n",
    "\n",
    "   - Một số bộ lọc trong các lớp tích chập thiếu tính đa dạng có thể hạn chế khả năng nhận dạng.\n",
    "   - So với các nhiệm vụ phân loại và phát hiện, phát hiện khuôn mặt là một nhiệm vụ phân loại nhị phân đầy thách thức, do đó, nó có thể cần số lượng bộ lọc trên mỗi lớp ít hơn.\n",
    "\n",
    "Để làm được điều này, nhóm tác giả giảm số lượng bộ lọc và thay đổi bộ lọc 5 × 5 thành bộ lọc 3 × 3 để giảm tính toán đồng thời tăng độ sâu để có được hiệu suất tốt hơn. Với những cải tiến này, so với kiến ​​trúc trước đó, có thể có được hiệu suất tốt hơn với thời gian chạy ít hơn.\n",
    "\n",
    "![comparisionspeed](./images/comparisionspeed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eaa8ba",
   "metadata": {},
   "source": [
    "\n",
    "#### PL.1. The Three Stages of MTCNN:\n",
    "\n",
    "**PL.1.1. Stage 1: The Proposal Network (P-Net)**\n",
    "\n",
    "![P-net](./images/P-net.jpeg)\n",
    "> P-Net (from MTCNN paper)\n",
    "\n",
    "* P-net là một Fully convolutional network (FCN). Sự khác biết giữa FCN và CNN đó là FCN không sử dụng dense layer. P-net được sử dụng để lấy các cửa sổ ứng viên và các vector hồi quy bao quanh.\n",
    "\n",
    "* Bounding box regression là công nghệ phổ biến để dự đoán khu vực của một đối tượng phân lớp, trong trường hợp này là khuôn mặt. Sau khi có tất cả các bounding box thì các bounding box này có thể bị chồng chéo lẫn nhau, cần thông qua một lớp lọc để cho ra khác khu vực không bị trùng lắp.\n",
    "\n",
    "\n",
    "##### PL.1.2. Stage 2: The Refine Network (R-Net)\n",
    "\n",
    "![R-net](./images/R-net.jpeg)\n",
    "> R-Net (from MTCNN paper)\n",
    "\n",
    "* Tất cả các ứng viên từ P-net sẽ được đưa vào R-net. R-net là một CNN bởi vì có một dense layer ở cuối stage. R-net giảm thêm số lượng ứng viên, thực hiện calibration các bounding box regression và NMS (non-maximum suppression) để hợp nhất các ứng viên trùng lắp.\n",
    "\n",
    "\n",
    "\n",
    "**PL.1.3. Stage 3: The Output Network (O-Net)**\n",
    "\n",
    "![O-net](./images/O-net.jpeg)\n",
    "> R-Net (from MTCNN paper)\n",
    "\n",
    "* Giai đoạn này tương tự như R-net, nhưng Output của network này mô tả chi tiết hơn về 5 điềm của khuông mặt mắt, mũi, miệng.\n",
    "\n",
    "\n",
    "#### PL.2. The Three Tasks of MTCNN:\n",
    "\n",
    "Trong tất cả các stage của Networks đều thực hiện 3 task: face/non-face classification, bounding box regression, facial landmark localization.\n",
    "\n",
    "**PL.2.1. Face classification:**\n",
    "* Sử dụng cross-entropy loss vì đây là bài toán phân 2 lớp, với mỗi mẫu $x_i$\n",
    "\n",
    "$$L_i^{det} = -(y_i^{det}\\log(p_i) + (1 - y_i^{det})(1-\\log(p_i)))$$\n",
    "\n",
    "*Trong đó, $p_i$ là xác xuất được tạo ra bớt net chỉ ra một sample là face. $y_i^{det} \\in {0, 1}$ là giá trị thật khuôn mặt hoặc không.\n",
    "\n",
    "**PL.2.2. Bounding box regression:**\n",
    "Với mỗi cửa sổ ứng viên, chúng ta dự đoán các vị trí tin tưởng tạo nên một bộ offset (left top, height, width). Việc huấn luyện là bài toán regression cho nên sử dụng Euclidean loss cho mỗi sameple $x_i$:\n",
    "\n",
    "$$L_i^{box} = \\parallel\\widehat{y}_i^{box} - y_i^{box}\\parallel_2^2$$\n",
    "\n",
    "Trong đó, $\\widehat{y}_i^{box}$ là các vị trí dự đoán được của net, $y_i^{box}$ là tọa độ thật. Chúng ta sẽ có bốn góc, bao gồm left top, height, width và $y_i^{box} \\in R^4$\n",
    "\n",
    "**PL.2.3. Facial Landmark localization:**\n",
    "Tương tự như bài toán regression và chúng ta sẽ đi minimize Euclidean distance:\n",
    "\n",
    "$$L_i^{landmark} = \\parallel\\widehat{y}_i^{landmark} - y_i^{landmark}\\parallel_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a6a2c2",
   "metadata": {},
   "source": [
    "## Trả lời issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934ed084",
   "metadata": {},
   "source": [
    "### Tại sao phải có 3 stage ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28d52d3",
   "metadata": {},
   "source": [
    "### Vai trò của R-Net "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
