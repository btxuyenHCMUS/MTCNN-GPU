{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue; text-align: center;\">Multi-task Cascaded Convolutional Networks (MTCNN) for Face Detection and Facial Landmark Alignment Using Parallel</h1>\n",
    "\n",
    "---\n",
    "\n",
    "<h2 style=\"color: gray; text-align: right;\">Members of Team:</h2>\n",
    "\n",
    "| MSSV | Full Name | ID Github |\n",
    "| ---- | ---- | -------- |\n",
    "| 1612835 | Bùi Trọng Xuyến | btxuyenhcmus |\n",
    "| 1612165 | Nguyễn Đào Vinh Hải | NDVHaiHCMUS |\n",
    "| 1612859 | Nguyễn Đình Hữu | NguyenDinhHuu-HCMUS |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Mô tả ứng dụng\n",
    "\n",
    "**Input:** Một tấm ảnh RGB, Video, Video livestream.\n",
    "\n",
    "**Output:** Một tấm ảnh RGB hoặc một video live trực tiếp được bounding các object và đánh dấu các vị trí trên khuôn mặt.\n",
    "\n",
    "### Ý nghĩa thực tế của ứng dụng:\n",
    "- Bài toán face detection là một bài toán mang lại rất nhiều lợi ích hiện nay: auto focus đối tượng trên máy ảnh, camera giám sát, smart house, tự động phát hiện khuông mặt để tag trong các mạng xã hội, bước đầu cho bài toán face reccorgnition,...\n",
    "- Khi chúng ta song song hoá được bài toán này thì sẽ đem lại lợi ích cao từ việc giảm chi phí tiền máy chủ, cho đến tiếp kiệm được thời gian.\n",
    "\n",
    "### Ứng dụng này cần được tăng tốc\n",
    "- Khi xử lý với video khi lượng frame đưa xuống quá nhanh, kết quả trả về của mô hình không kiệp đáp ứng tạo nên độ trễ.\n",
    "\n",
    "### Tiềm năng song song hóa\n",
    "- Song song hóa các phép tích chập trong mô hình.\n",
    "- Các phép toán trên matrix.\n",
    "\n",
    "\n",
    "![index](./images/examples.png)\n",
    "> Nguồn ảnh: [https://kpzhang93.github.io/MTCNN_face_detection_alignment/](https://kpzhang93.github.io/MTCNN_face_detection_alignment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cài đặt tuần tự"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ý tưởng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Các phương pháp xử lý ảnh truyền thống xử lý tích chập để rút trích đặt trưng từ đó chọn lọc ra hình ảnh khuôn mặt. Sử dụng mạng học sâu để huấn luận các mạng neural cho ra tập các tham số huận luyện linh động hơn việc đưa ra các tham số cho từng bài toán rút trích đặc trưng cụ thể.\n",
    "* Thay vì xử lý tất cả các công việc trong cùng một mạng, thì chia ra làm ba giai đoạn thực hiện nhiều nhiệm vụ để cho ra kết quả với thứ tự kết quả của mạng trước sẽ là đầu vào của mạng sau.\n",
    "* Với mỗi bức ảnh đưa vào sẽ thực hiện việc lọc các cửa số khung mặt đề xuất, tốc độ nhanh không yêu cầu độ chính xác cao, số lượng khuông mặt có thể nhiều hơn. Tiếp tục phân tích trên tập dữ liệu khuôn mặt đề xuất và cho ra kết quả chính xác hơn. Lọc kết quả cuối cùng để cho ra được các cửa số khuôn mặt có độ chính xác tương đối cao nhất.\n",
    "\n",
    "* Từ việc xử lí trên từng bức ảnh, phát triển lên phát hiện khuôn mặt trên video hoặc video livestream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training data:**\n",
    "- Nhóm sự dụng network được train sẵn trên bộ dữ liệu WIDER FACE bao gồm 32,203 images và label 393,703 faces.\n",
    "- Bộ dữ liệu được chia thành các tập training, validation, testing với tỉ lệ 40% / 10% / 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Đánh giá tính đúng đắn của mô hình**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để đánh giá tính đúng đắn của mô hình, nhóm của tác giả đã so sánh với các phương pháp khác trong SOTA trên bộ dự liệu phát hiện khuôn mặt và điểm chuẩn FDDB, WINDER FACE, và dấu mốc trên khuôn mặt được chú thích trong điểm chuẩn AFLW:\n",
    "\n",
    "- Tập dữ liệu FDDB chứa các chú thích cho 5.171 khuôn mặt trong một tập hợp gồm 2.845 hình ảnh.\n",
    "- Bộ dữ liệu WIDER FACE bao gồm 393.703 hộp giới hạn khuôn mặt được gắn nhãn trong 32.203 hình ảnh trong đó 50% trong số đó để thử nghiệm (chia thành ba tập con theo độ khó của hình ảnh), 40% dành cho đào tạo và phần còn lại để xác thực.\n",
    "- AFLW chứa chú thích các mốc khuôn mặt cho 24.386 khuôn mặt và chúng tôi sử dụng cùng một tập hợp con thử nghiệm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Evaluation](./images/evaluation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation on face alignment**\n",
    "\n",
    "Nhóm tác giả so sánh performance với các phương pháp RCPR, TSPM, Luxand face SDK, ESR, CDM, SDM, và TCDCN. Sai số trung bình được đo bằng khoảng cách giữa các điểm mốc ước tính và độ chân thực trên mặt đất, và được chuẩn hóa đối với khoảng cách giữa hai mắt.\n",
    "\n",
    "![Alignment](./images/alignment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improvements with previous CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhiều CNN đã được thiết kế để nhận diện khuôn mặt. Tuy nhiên, nhóm tác giả nhận thấy rằng hiệu suất của nó có thể bị hạn chế bởi các sự kiện sau:\n",
    "\n",
    "   - Một số bộ lọc trong các lớp tích chập thiếu tính đa dạng có thể hạn chế khả năng phân biệt của chúng.\n",
    "   - So với các nhiệm vụ phân loại và phát hiện phản đối nhiều lớp khác, phát hiện khuôn mặt là một nhiệm vụ phân loại nhị phân đầy thách thức, do đó, nó có thể cần số lượng bộ lọc trên mỗi lớp ít hơn.\n",
    "\n",
    "Để làm được điều này, nhóm tác giả giảm số lượng bộ lọc và thay đổi bộ lọc 5 × 5 thành bộ lọc 3 × 3 để giảm tính toán đồng thời tăng độ sâu để có được hiệu suất tốt hơn. Với những cải tiến này, so với kiến ​​trúc trước đó, có thể có được hiệu suất tốt hơn với thời gian chạy ít hơn.\n",
    "\n",
    "![comparisionspeed](./images/comparisionspeed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các bước thực hiện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sơ đồ thực hiện nhận diện khuôn mặt trong MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![inputimage](./images/1.png)\n",
    "> Nguồn ảnh: [https://manutdzou.github.io/2017/01/24/mtcnn.html](https://manutdzou.github.io/2017/01/24/mtcnn.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Các bước thực hiện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* B1: Cho ảnh đầu vào image pyramid với nhiều kích cỡ khác nhau. (Từ ảnh gốc cho ảnh down scale thành 10 bức ảnh có kích thước nhỏ hơn).\n",
    "\n",
    "* B2: Input của bước này các bức ảnh đã được pyramid image. Ở bước này P-Net có nhiệm vụ là xác nhận các windows có chứa khuôn mặt nhanh nhưng thiếu chính xác. Sau khi có các bounding box ở P-Net chúng ta sẽ dùng NMS và bounding box regression để giảm số lượng của các bounding box đã được dự đoán ở P-Net. Sau cùng ta có được output là các face classification và bounding box regression.\n",
    "\n",
    "![p-net](./images/pnet.png)\n",
    "> Nguồn ảnh: [https://www.pytorials.com/face-detection-matching-using-facenet/](https://www.pytorials.com/face-detection-matching-using-facenet/)\n",
    "\n",
    "* B3: Input của bước này là các output bounding box của B2. Ở đây thì R-Net có độ sâu về cấu trúc so với P-Net. Nhiệm vụ chính của R-Net là lọc các bounding box của P-Net + NMS + bounding box regression. Cũng như P-Net sau khi lọc các bounding box ở R-Net thì chúng ta cho qua NMS và bounding box regression để giảm số lượng của các bounding box đã được dự đoán. Ouput ở bước này các face classification và bounding box regression.\n",
    "\n",
    "![r-net](./images/rnet.png)\n",
    "> Nguồn ảnh: [https://www.pytorials.com/face-detection-matching-using-facenet/](https://www.pytorials.com/face-detection-matching-using-facenet/)\n",
    "\n",
    "* B4: Input ở bước này là các output bounding box của B3. Tương tự như R-Net, nhiệm vụ chính của O-Net là lọc các bounding box. Sau cùng NMS và bounding box regression có nhiệm vụ lọc lại bounding box chính xác và đánh dấu các vị trí trên khuôn mặt được phát hiện. \n",
    "\n",
    "![o-net](./images/onet.png)\n",
    "> Nguồn ảnh: [https://www.pytorials.com/face-detection-matching-using-facenet/](https://www.pytorials.com/face-detection-matching-using-facenet/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đánh giá code tuần tự"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đánh giá code tuần tự không jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhóm viết lại code convolution2d trong torch. Sau đây là kết quả dánh giá sau khi chạy chương trên tập ảnh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![family](./images/r-family.png)\n",
    "> Ảnh: family.jpeg 600x400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| family.jpeg | P-Net | R-Net | O-Net |\n",
    "| --- | --- | --- | --- |\n",
    "| Thời gian chạy | 529000ms | 288000ms | 337000ms |\n",
    "| Số lượng bounding box | 192 | 36 | 23 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./images/r-test.png)\n",
    "> Ảnh: test.jpg (nguồn: https://www.istockphoto.com/photos/group-of-people) 612x408"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| test.jpg | P-Net | R-Net | O-Net |\n",
    "| --- | --- | --- | --- |\n",
    "| Thời gian chạy | 540000ms | 766000ms | 787000ms |\n",
    "| Số lượng bounding box | 529 | 80 | 52 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./images/r-test2.png)\n",
    "> Ảnh: test2.jpg 612x408"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| test2.jpg | P-Net | R-Net | O-Net |\n",
    "| --- | --- | --- | --- |\n",
    "| Thời gian chạy | 931000ms | 1971000ms | 2357000ms |\n",
    "| Số lượng bounding box | 1334 | 258 | 137 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jit code convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi code tuần tự xong nhóm thực hiện jit code convolution2d. Nhóm thực nghiệm code jit dựa trên nhiều tập ảnh khác nhau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bảng đánh giá thời gian chạy trên ảnh family.jpeg có kích thước $600x400$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![family](./images/r-jit-family.png)\n",
    "> Ảnh: family.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| family.jpeg | P-Net | R-Net | O-Net |\n",
    "| --- | --- | --- | --- |\n",
    "| Thời gian chạy | 1460ms | 566ms | 606ms |\n",
    "| Số lượng bounding box | 192 | 36 | 23 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bảng đánh giá thời gian chạy trên ảnh oscar1.jpg có kích thước $4646x1800$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![oscar1](./images/r-jit-oscar.png)\n",
    "> Ảnh: oscar1.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| oscar1.jpg | P-Net | R-Net | O-Net |\n",
    "| --- | --- | --- | --- |\n",
    "| Thời gian chạy | 34200ms | 202000ms | 45500ms |\n",
    "| Số lượng bounding box | 11081 | 1613 | 967 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bảng đánh giá thời gian chạy trên ảnh test.jpg có kích thước $612x408$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./images/r-jit-test.png)\n",
    "> Ảnh: test.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| test.jpg | P-Net | R-Net | O-Net |\n",
    "| --- | --- | --- | --- |\n",
    "| Thời gian chạy | 1510ms | 1580ms | 1450ms |\n",
    "| Số lượng bounding box | 529 | 80 | 53 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bảng đánh giá thời gian chạy trên ảnh test2.jpg có kích thước $768x512$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./images/r-jit-test2.png)\n",
    "> Ảnh: test2.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| test2.jpg | P-Net | R-Net | O-Net |\n",
    "| --- | --- | --- | --- |\n",
    "| Thời gian chạy | 2240ms | 4140ms | 4059ms |\n",
    "| Số lượng bounding box | 1334 | 258 | 138 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cài đặt song song (trên GPU)\n",
    "### Ý tưởng\n",
    "**Conv2d**\n",
    "* Toàn bộ net trong mạng đều sử dụng tích chập với các kích thước khác nhau tùy thuộc vào mỗi giai đoạn.\n",
    "* Ban đầu nhóm sẽ dùng jit(parallel=True) để thử chạy song song trên host\n",
    "* Sau khi jit(parallel=True) chạy thành công nhóm tiếp tục sử dụng cuda.jit để chạy chương trình song song trên GPU\n",
    "* Trong MTCNN mỗi stage gồm các khối convolution gồm 4 chiều: số lượng khối convolution, trong mỗi khối sẽ chứa bao nhiêu lớp và tham số trong mỗi lớp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ý tưởng**\n",
    "* Nhóm sẽ biến đổi không gian 4 chiều thành 1 không gian 2 chiều rồi sử dụng cuda.jit để đưa vào các thread xử lí song song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các bước thực hiện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* B1: Nhóm sẽ thực hiện song song trên host bằng việc sử dụng function của numba là jit(parallel=True). \n",
    "* B2: Sau khi thực hiện jit parallel. Nhóm tiếp tục biến đổi các khối convolution 4 chiều thành mảng 2 chiều.\n",
    "* B3: Sau khi có được mảng chiều, ta sẽ đưa mảng 2 chiều đó vào cuda.jit để xử lí\n",
    "* \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đánh giá code song song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi thực hiện cuda.jit và jit parallel thì nhóm có một số đánh giá về kết quả như sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả chạy trên ảnh family.jpeg có kích thước 600x400:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Kết quả ảnh chạy trên jit parallel:\n",
    "![jp-family](./images/jp-family.png)\n",
    "* Thời gian chạy: 1.53 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Kết quả ảnh chạy trên cuda.jit:\n",
    "![cuda-family](./images/cuda-family.png)\n",
    "* Thời gian chạy: 3.35 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả chạy trên ảnh test.jpg có kích thước 612x408:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jp-test](./images/jp-test.png)\n",
    "* Thời gian chạy: 1.47 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cuda-test](./images/cuda-test.png)\n",
    "* Thời gian chạy: 5.71 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả chạy trên ảnh test.jpg có kích thước 768x512:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jp-test2](./images/jp-test2.png)\n",
    "* Thời gian chạy: 3.34 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cuda-test2](./images/cuda-test2.png)\n",
    "* Thời gian chạy: 11.7 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Nhìn lại quá trình làm đồ án"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tài liệu tham khảo\n",
    "\n",
    "- [x] [PDF report](https://arxiv.org/pdf/1604.02878.pdf)\n",
    "- [x] [Document Guide](https://medium.com/@iselagradilla94/multi-task-cascaded-convolutional-networks-mtcnn-for-face-detection-and-facial-landmark-alignment-7c21e8007923)\n",
    "- [x] [MTCNN-Pytorch](https://github.com/TropComplique/mtcnn-pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phục lục"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### PL.1. The Three Stages of MTCNN:\n",
    "\n",
    "**PL.1.1. Stage 1: The Proposal Network (P-Net)**\n",
    "\n",
    "![P-net](./images/P-net.jpeg)\n",
    "> P-Net (from MTCNN paper)\n",
    "\n",
    "* P-net là một Fully convolutional network (FCN). Sự khác biết giữa FCN và CNN đó là FCN không sử dụng dense layer. P-net được sử dụng để lấy các cửa sổ ứng viên và các vector hồi quy bao quanh.\n",
    "\n",
    "* Bounding box regression là công nghệ phổ biến để dự đoán khu vực của một đối tượng phân lớp, trong trường hợp này là khuôn mặt. Sau khi có tất cả các bounding box thì các bounding box này có thể bị chồng chéo lẫn nhau, cần thông qua một lớp lọc để cho ra khác khu vực không bị trùng lắp.\n",
    "\n",
    "\n",
    "##### PL.1.2. Stage 2: The Refine Network (R-Net)\n",
    "\n",
    "![R-net](./images/R-net.jpeg)\n",
    "> R-Net (from MTCNN paper)\n",
    "\n",
    "* Tất cả các ứng viên từ P-net sẽ được đưa vào R-net. R-net là một CNN bởi vì có một dense layer ở cuối stage. R-net giảm thêm số lượng ứng viên, thực hiện calibration các bounding box regression và NMS (non-maximum suppression) để hợp nhất các ứng viên trùng lắp.\n",
    "\n",
    "\n",
    "\n",
    "**PL.1.3. Stage 3: The Output Network (O-Net)**\n",
    "\n",
    "![O-net](./images/O-net.jpeg)\n",
    "> R-Net (from MTCNN paper)\n",
    "\n",
    "* Giai đoạn này tương tự như R-net, nhưng Output của network này mô tả chi tiết hơn về 5 điềm của khuông mặt mắt, mũi, miệng.\n",
    "\n",
    "\n",
    "#### PL.2. The Three Tasks of MTCNN:\n",
    "\n",
    "Trong tất cả các stage của Networks đều thực hiện 3 task: face/non-face classification, bounding box regression, facial landmark localization.\n",
    "\n",
    "**PL.2.1. Face classification:**\n",
    "* Sử dụng cross-entropy loss vì đây là bài toán phân 2 lớp, với mỗi mẫu $x_i$\n",
    "\n",
    "$$L_i^{det} = -(y_i^{det}\\log(p_i) + (1 - y_i^{det})(1-\\log(p_i)))$$\n",
    "\n",
    "*Trong đó, $p_i$ là xác xuất được tạo ra bớt net chỉ ra một sample là face. $y_i^{det} \\in {0, 1}$ là giá trị thật khuôn mặt hoặc không.\n",
    "\n",
    "**PL.2.2. Bounding box regression:**\n",
    "Với mỗi cửa sổ ứng viên, chúng ta dự đoán các vị trí tin tưởng tạo nên một bộ offset (left top, height, width). Việc huấn luyện là bài toán regression cho nên sử dụng Euclidean loss cho mỗi sameple $x_i$:\n",
    "\n",
    "$$L_i^{box} = \\parallel\\widehat{y}_i^{box} - y_i^{box}\\parallel_2^2$$\n",
    "\n",
    "Trong đó, $\\widehat{y}_i^{box}$ là các vị trí dự đoán được của net, $y_i^{box}$ là tọa độ thật. Chúng ta sẽ có bốn góc, bao gồm left top, height, width và $y_i^{box} \\in R^4$\n",
    "\n",
    "**PL.2.3. Facial Landmark localization:**\n",
    "Tương tự như bài toán regression và chúng ta sẽ đi minimize Euclidean distance:\n",
    "\n",
    "$$L_i^{landmark} = \\parallel\\widehat{y}_i^{landmark} - y_i^{landmark}\\parallel_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trả lời issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tại sao phải có 3 stage ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vai trò của R-Net "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
